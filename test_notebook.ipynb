{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7b6bc327",
   "metadata": {},
   "source": [
    "### *0. Imports*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b324fce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import yaml\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from pathlib import Path\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bba0e3ba",
   "metadata": {},
   "source": [
    "\n",
    "### *1. Data Cleaning* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72de76e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Removing redundant data from GOOSE dataset download'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"Removing redundant data from GOOSE dataset download keeping only RGB images\"\"\"\n",
    "#source_dir = Path(r\"C:\\Users\\maxlars\\UGV research pipeline\\Goose_dataset\\images\\val\")\n",
    "#target_dir = Path(r\"C:\\Users\\maxlars\\UGV research pipeline\\Goose_dataset\\processed_rgb\")\n",
    "\n",
    "#target_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "#print(\"Starting trimming process...\")\n",
    "#\n",
    "#for root, dirs, files in os.walk(source_dir):\n",
    "#    for file in files:\n",
    "#        if \"vis\" in file.lower() and file.endswith((\".png\", \".jpg\")):\n",
    "#            rel_path = os.path.relpath(root, source_dir)\n",
    "#            dest_folder = target_dir / rel_path\n",
    "#            dest_folder.mkdir(parents=True, exist_ok=True)\n",
    "#            \n",
    "#            shutil.copy2(os.path.join(root, file), dest_folder / file)\n",
    "#\n",
    "#print(f\"Done! Cleaned RGB images are in: {target_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33fc7ff2",
   "metadata": {},
   "source": [
    "### *2. Projection*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ad24da37",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from pathlib import Path\n",
    "import re\n",
    "\n",
    "class GooseQueryProjector:\n",
    "    def __init__(self, yaml_path, sequence_start_time_ns=0):\n",
    "        self.yaml_path = Path(yaml_path)\n",
    "        # Anchor for 4D T-dimension\n",
    "        self.start_time_ns = sequence_start_time_ns \n",
    "        self.load_calibration()\n",
    "\n",
    "    def load_calibration(self):\n",
    "        \"\"\"Loads camera parameters from the windshield_vis.yaml.\"\"\"\n",
    "        with open(self.yaml_path, 'r') as f:\n",
    "            data = yaml.safe_load(f)\n",
    "        \n",
    "        # 1. Extracted Intrinsics\n",
    "        self.img_width = data['image_width']\n",
    "        self.img_height = data['image_height']\n",
    "        self.K = torch.tensor(data['camera_matrix']['data']).view(3, 3).float()\n",
    "        \n",
    "        # 2. Distortion (Plumb Bob Model)\n",
    "        self.D = torch.tensor(data['distortion_coefficients']['data']).float()\n",
    "        \n",
    "        # 3. Projection Matrix\n",
    "        self.P = torch.tensor(data['projection_matrix']['data']).view(3, 4).float()\n",
    "\n",
    "    def get_relative_timestamp(self, filename):\n",
    "        \"\"\"\n",
    "        Parses nanoseconds from filename and calculates relative T for 4D Queries.\n",
    "        Example: '..._1658494234334310308_windshield_vis.png'\n",
    "        \"\"\"\n",
    "        match = re.search(r'(\\d{19})', filename)\n",
    "        if match:\n",
    "            file_time_ns = int(match.group(1))\n",
    "            # Convert to seconds relative to 'time_machine' start\n",
    "            return (file_time_ns - self.start_time_ns) / 1e9\n",
    "        return 0.0\n",
    "\n",
    "    def undistort_image(self, image_tensor):\n",
    "        \"\"\"Pre-processes RGB images to align straight lines in off-road terrain.\"\"\"\n",
    "        h, w = image_tensor.shape[-2:]\n",
    "        grid_y, grid_x = torch.meshgrid(\n",
    "            torch.linspace(-1, 1, h), \n",
    "            torch.linspace(-1, 1, w), \n",
    "            indexing='ij'\n",
    "        )\n",
    "        \n",
    "        u = (grid_x + 1) * (w - 1) / 2\n",
    "        v = (grid_y + 1) * (h - 1) / 2\n",
    "        \n",
    "        x = (u - self.K[0, 2]) / self.K[0, 0]\n",
    "        y = (v - self.K[1, 2]) / self.K[1, 1]\n",
    "        \n",
    "        r2 = x**2 + y**2\n",
    "        radial = (1 + self.D[0]*r2 + self.D[1]*r2**2 + self.D[4]*r2**3)\n",
    "        x_dist = x * radial + (2*self.D[2]*x*y + self.D[3]*(r2 + 2*x**2))\n",
    "        y_dist = y * radial + (self.D[2]*(r2 + 2*y**2) + 2*self.D[3]*x*y)\n",
    "        \n",
    "        u_dist = self.K[0, 0] * x_dist + self.K[0, 2]\n",
    "        v_dist = self.K[1, 1] * y_dist + self.K[1, 2]\n",
    "        \n",
    "        grid = torch.stack([2 * u_dist / (w - 1) - 1, 2 * v_dist / (h - 1) - 1], dim=-1).unsqueeze(0)\n",
    "        return F.grid_sample(image_tensor, grid, align_corners=True)\n",
    "\n",
    "    def project_4d_query(self, points_3d, ego_pose, relative_t):\n",
    "        \"\"\"Projects world-space voxels into 2D based on current UGV pose and time.\"\"\"\n",
    "        points_homo = torch.cat([points_3d, torch.ones(len(points_3d), 1)], dim=-1)\n",
    "        # Transform P_world to P_camera\n",
    "        points_cam = (ego_pose @ points_homo.T).T\n",
    "        \n",
    "        z = points_cam[:, 2:3].clamp(min=1e-3)\n",
    "        pixels_2d = (self.K @ points_cam[:, :3].T).T / z\n",
    "        \n",
    "        return pixels_2d[:, :2], relative_t"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16b3e524",
   "metadata": {},
   "source": [
    "### *3. Dataset*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ef4901b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from PIL import Image\n",
    "\n",
    "class GooseTripletDataset(Dataset):\n",
    "    def __init__(self, image_root, projector, transform=None):\n",
    "        self.image_root = Path(image_root)\n",
    "        self.projector = projector\n",
    "        self.transform = transform\n",
    "        self.samples = self._build_triplets()\n",
    "\n",
    "    def _build_triplets(self):\n",
    "        triplets = []\n",
    "        # Iteratively traverse sorted subfolders\n",
    "        for seq_folder in sorted(self.image_root.iterdir()):\n",
    "            if not seq_folder.is_dir(): continue\n",
    "            images = sorted([f for f in seq_folder.glob(\"*rgb.png\")])\n",
    "            \n",
    "            # Create (prev, current, next) triplets\n",
    "            for i in range(1, len(images) - 1):\n",
    "                triplets.append({\n",
    "                    'prev': images[i-1],\n",
    "                    'curr': images[i],\n",
    "                    'next': images[i+1],\n",
    "                    'seq_path': seq_folder\n",
    "                })\n",
    "        return triplets\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        t = self.samples[idx]\n",
    "        \n",
    "        # Load images\n",
    "        img_curr = Image.open(t['curr']).convert('RGB')\n",
    "        img_prev = Image.open(t['prev']).convert('RGB')\n",
    "        img_next = Image.open(t['next']).convert('RGB')\n",
    "\n",
    "        # Get relative 4D timestamps\n",
    "        rel_t = self.projector.get_relative_timestamp(t['curr'].name)\n",
    "        \n",
    "        return {\n",
    "            'images': torch.stack([img_prev, img_curr, img_next]), # (3, C, H, W)\n",
    "            'rel_t': rel_t,\n",
    "            'seq_name': t['seq_path'].name\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a15d2031",
   "metadata": {},
   "source": [
    "### *4. Initialize setup*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4216ee53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded schema: SpecMetaData.json\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import yaml\n",
    "import torch\n",
    "import re\n",
    "from pathlib import Path\n",
    "\n",
    "# --- Correct Pathing ---\n",
    "base_path = Path(r\"C:\\Users\\maxlars\\UGV_research_pipeline\\Goose_dataset\")\n",
    "\n",
    "# The schema is in the 'common' folder\n",
    "spec_schema_path = base_path / \"SpecMetaData.json\" \n",
    "\n",
    "# Calibration is in its own dedicated folder\n",
    "calibration_file = base_path / \"calibration\" / \"windshield_vis.yaml\" \n",
    "\n",
    "# Your processed chronological images\n",
    "image_root = base_path / \"processed_rgb\" \n",
    "\n",
    "# --- 1. Load the JSON Schema ---\n",
    "with open(spec_schema_path, 'r') as f:\n",
    "    spec_schema = json.load(f)\n",
    "    print(f\"Loaded schema: {spec_schema['title']}\") #\n",
    "\n",
    "# --- 2. Iterative Sequence Processing ---\n",
    "for sequence_folder in sorted(image_root.iterdir()):\n",
    "    if not sequence_folder.is_dir():\n",
    "        continue\n",
    "        \n",
    "    # Metadata file for the specific sequence\n",
    "    sequence_metadata_path = sequence_folder / \"metadata.yaml\"\n",
    "    \n",
    "    if not sequence_metadata_path.exists():\n",
    "        continue\n",
    "\n",
    "    with open(sequence_metadata_path, 'r') as f:\n",
    "        seq_metadata = yaml.safe_load(f)\n",
    "    \n",
    "    # Extract the 'time_machine' UNIX epoch (ns) iteratively\n",
    "    start_ns = seq_metadata['info']['time_machine'] \n",
    "    \n",
    "    # Initialize Projector with the sequence-specific temporal anchor\n",
    "    projector = GooseQueryProjector(\n",
    "        yaml_path=calibration_file, \n",
    "        sequence_start_time_ns=start_ns\n",
    "    )\n",
    "    \n",
    "    print(f\"\\nProcessing Sequence: {sequence_folder.name}\")\n",
    "    \n",
    "    # Get sorted files for chronological 4D learning\n",
    "    image_files = sorted([f for f in os.listdir(sequence_folder) if \"rgb\" in f])\n",
    "    \n",
    "    for fname in image_files[:2]:\n",
    "        rel_t = projector.get_relative_timestamp(fname)\n",
    "        print(f\"  Image: {fname} | 4D T-Feature: {rel_t:.4f}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3053b65b",
   "metadata": {},
   "source": [
    "### *5. Model Initialization*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61d30739",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SelfSupervisedOccupancyLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.l1_loss = nn.L1Loss()\n",
    "\n",
    "    def forward(self, pred_image, target_image):\n",
    "        \"\"\"\n",
    "        pred_image: The image reconstructed by projecting 3D queries into time T+1\n",
    "        target_image: The actual RGB image at time T+1\n",
    "        \"\"\"\n",
    "        # 1. Photometric Loss (L1)\n",
    "        l1 = self.l1_loss(pred_image, target_image)\n",
    "        \n",
    "        # 2. Add SSIM for structural consistency (optional but recommended)\n",
    "        # ssim_loss = 1 - ssim(pred_image, target_image)\n",
    "        \n",
    "        return l1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
