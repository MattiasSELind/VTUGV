{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7b6bc327",
   "metadata": {},
   "source": [
    "### *0. Imports*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b324fce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import yaml\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import torch\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bba0e3ba",
   "metadata": {},
   "source": [
    "\n",
    "### *1. Data Cleaning* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72de76e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting trimming process...\n",
      "Done! Cleaned RGB images are in: C:\\Users\\maxlars\\UGV research pipeline\\Goose_dataset\\processed_rgb\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Removing redundant data from GOOSE dataset download\"\"\"\n",
    "#source_dir = Path(r\"C:\\Users\\maxlars\\UGV research pipeline\\Goose_dataset\\images\\val\")\n",
    "#target_dir = Path(r\"C:\\Users\\maxlars\\UGV research pipeline\\Goose_dataset\\processed_rgb\")\n",
    "\n",
    "#target_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "#print(\"Starting trimming process...\")\n",
    "#\n",
    "#for root, dirs, files in os.walk(source_dir):\n",
    "#    for file in files:\n",
    "#        if \"vis\" in file.lower() and file.endswith((\".png\", \".jpg\")):\n",
    "#            rel_path = os.path.relpath(root, source_dir)\n",
    "#            dest_folder = target_dir / rel_path\n",
    "#            dest_folder.mkdir(parents=True, exist_ok=True)\n",
    "#            \n",
    "#            shutil.copy2(os.path.join(root, file), dest_folder / file)\n",
    "#\n",
    "#print(f\"Done! Cleaned RGB images are in: {target_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3922f7d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'ajv' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "!ajv validate --spec=draft2020 --strict-schema=log - -s ./metadata-scheme.json -d ./metadata.yml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33fc7ff2",
   "metadata": {},
   "source": [
    "### *2. Data Pre-processing and 3D projection*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad24da37",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GooseQueryProjector:\n",
    "    def __init__(self, yaml_path):\n",
    "        self.yaml_path = Path(yaml_path)\n",
    "        self.load_calibration()\n",
    "\n",
    "    def load_calibration(self):\n",
    "        \"\"\"Loads camera parameters from the windshield_vis.yaml.\"\"\"\n",
    "        with open(self.yaml_path, 'r') as f:\n",
    "            data = yaml.safe_load(f)\n",
    "        \n",
    "        self.img_width = data['image_width']\n",
    "        self.img_height = data['image_height']\n",
    "        \n",
    "        k_data = data['camera_matrix']['data']\n",
    "        self.K = torch.tensor(k_data).view(3, 3).float()\n",
    "        \n",
    "        d_data = data['distortion_coefficients']['data']\n",
    "        self.D = torch.tensor(d_data).float()\n",
    "        \n",
    "        p_data = data['projection_matrix']['data']\n",
    "        self.P = torch.tensor(p_data).view(3, 4).float()\n",
    "\n",
    "    def undistort_image(self, image_tensor):\n",
    "        \"\"\"\n",
    "        Uses grid_sample to undistort the RGB image before feature extraction.\n",
    "        image_tensor: (B, C, H, W)\n",
    "        \"\"\"\n",
    "        h, w = image_tensor.shape[-2:]\n",
    "        \n",
    "        grid_y, grid_x = torch.meshgrid(\n",
    "            torch.linspace(-1, 1, h), \n",
    "            torch.linspace(-1, 1, w), \n",
    "            indexing='ij'\n",
    "        )\n",
    "        \n",
    "        u = (grid_x + 1) * (w - 1) / 2\n",
    "        v = (grid_y + 1) * (h - 1) / 2\n",
    "        \n",
    "        x = (u - self.K[0, 2]) / self.K[0, 0]\n",
    "        y = (v - self.K[1, 2]) / self.K[1, 1]\n",
    "        \n",
    "        r2 = x**2 + y**2\n",
    "        radial = (1 + self.D[0]*r2 + self.D[1]*r2**2 + self.D[4]*r2**3)\n",
    "        x_dist = x * radial + (2*self.D[2]*x*y + self.D[3]*(r2 + 2*x**2))\n",
    "        y_dist = y * radial + (self.D[2]*(r2 + 2*y**2) + 2*self.D[3]*x*y)\n",
    "        \n",
    "        u_dist = self.K[0, 0] * x_dist + self.K[0, 2]\n",
    "        v_dist = self.K[1, 1] * y_dist + self.K[1, 2]\n",
    "        \n",
    "        grid = torch.stack([\n",
    "            2 * u_dist / (w - 1) - 1, \n",
    "            2 * v_dist / (h - 1) - 1\n",
    "        ], dim=-1).unsqueeze(0)\n",
    "        \n",
    "        return F.grid_sample(image_tensor, grid, align_corners=True)\n",
    "\n",
    "    def project_4d_query(self, points_3d, ego_pose, timestamp):\n",
    "        \"\"\"\n",
    "        Projects a 3D point into the 2D frame using ego-motion at time T.\n",
    "        points_3d: (N, 3) voxels in world coordinates\n",
    "        ego_pose: (4, 4) matrix for the UGV at 'timestamp'\n",
    "        \"\"\"\n",
    "        points_homo = torch.cat([points_3d, torch.ones(len(points_3d), 1)], dim=-1)\n",
    "        points_cam = (ego_pose @ points_homo.T).T\n",
    "        \n",
    "        pixels_2d = (self.K @ points_cam[:, :3].T).T / z\n",
    "        \n",
    "        return pixels_2d[:, :2], timestamp\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
